{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d72c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastparquet\n",
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d975a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/train_final_dataset.snappy.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2ef83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_similarity'] = df['image_similarity'].fillna(0)\n",
    "\n",
    "df[['is_same_location', 'is_same_region']] = df[['is_same_location', 'is_same_region']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fc373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Совпадение категорий и параметров\n",
    "df['same_category'] = (df['base_category_name'] == df['cand_category_name']).astype(int)\n",
    "df['same_subcategory'] = (df['base_subcategory_name'] == df['cand_subcategory_name']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1f62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_diff_pct'] = 2 * abs(df['base_price'] - df['cand_price']) / (df['base_price'] + df['cand_price'] + 1e-6)\n",
    "\n",
    "df['images_diff'] = df['base_count_images'] - df['cand_count_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d6c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'base_price', \n",
    "    'cand_price',\n",
    "    'price_diff_pct',\n",
    "    'base_count_images',\n",
    "    'cand_count_images',\n",
    "    'images_diff',\n",
    "    'common_params_count',\n",
    "    'same_values_count'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae0a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_param1'] = df['base_param1'].replace('', 'Не указано')\n",
    "df['cand_param1'] = df['cand_param1'].replace('', 'Не указано')\n",
    "df['same_param1'] = (df['base_param1'] == df['cand_param1']).astype(int)\n",
    "le_param1 = LabelEncoder()\n",
    "all_values = pd.concat([df['base_param1'], df['cand_param1']]).unique()\n",
    "le_param1.fit(all_values)\n",
    "\n",
    "df['base_param1_encoded'] = le_param1.transform(df['base_param1'])\n",
    "df['cand_param1_encoded'] = le_param1.transform(df['cand_param1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19490e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_param2'] = df['base_param2'].replace('', 'Не указано')\n",
    "df['cand_param2'] = df['cand_param2'].replace('', 'Не указано')\n",
    "df['same_param2'] = (df['base_param2'] == df['cand_param2']).astype(int)\n",
    "le_param2 = LabelEncoder()\n",
    "all_values = pd.concat([df['base_param2'], df['cand_param2']]).unique()\n",
    "le_param2.fit(all_values)\n",
    "\n",
    "df['base_param2_encoded'] = le_param2.transform(df['base_param2'])\n",
    "df['cand_param2_encoded'] = le_param2.transform(df['cand_param2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea003722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500000 entries, 0 to 499999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   base_price              500000 non-null  float64\n",
      " 1   cand_price              500000 non-null  float64\n",
      " 2   base_count_images       500000 non-null  float64\n",
      " 3   cand_count_images       500000 non-null  float64\n",
      " 4   is_same_location        500000 non-null  int32  \n",
      " 5   is_same_region          500000 non-null  int32  \n",
      " 6   is_double               500000 non-null  int64  \n",
      " 7   common_params_count     500000 non-null  float64\n",
      " 8   same_values_count       500000 non-null  float64\n",
      " 9   image_similarity        500000 non-null  float64\n",
      " 10  basic_image_similarity  500000 non-null  float64\n",
      " 11  title_similarity        500000 non-null  float64\n",
      " 12  description_similarity  500000 non-null  float64\n",
      " 13  same_category           500000 non-null  int32  \n",
      " 14  same_subcategory        500000 non-null  int32  \n",
      " 15  price_diff_pct          500000 non-null  float64\n",
      " 16  images_diff             500000 non-null  float64\n",
      " 17  same_param1             500000 non-null  int32  \n",
      " 18  base_param1_encoded     500000 non-null  int32  \n",
      " 19  cand_param1_encoded     500000 non-null  int32  \n",
      " 20  same_param2             500000 non-null  int32  \n",
      " 21  base_param2_encoded     500000 non-null  int32  \n",
      " 22  cand_param2_encoded     500000 non-null  int32  \n",
      "dtypes: float64(12), int32(10), int64(1)\n",
      "memory usage: 72.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    'base_item_id', 'cand_item_id', 'group_id', 'action_date',\n",
    "    'base_title', 'cand_title', 'base_description', 'cand_description',\n",
    "    'base_json_params', 'cand_json_params',\n",
    "    'base_title_image', 'cand_title_image',\n",
    "    'base_category_name', 'cand_category_name',\n",
    "    'base_subcategory_name', 'cand_subcategory_name',\n",
    "    'base_param1', 'cand_param1',\n",
    "    'base_param2', 'cand_param2',\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efaba2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'base_price', 'cand_price', 'price_diff_pct',\n",
    "    'base_count_images', 'cand_count_images', 'images_diff',\n",
    "    \n",
    "    'title_similarity', 'description_similarity',\n",
    "    'image_similarity', 'basic_image_similarity',\n",
    "    \n",
    "    'same_category', 'same_subcategory',\n",
    "    'common_params_count', 'same_values_count',\n",
    "    \n",
    "    'is_same_location', 'is_same_region',\n",
    "\n",
    "    'same_param1', 'base_param1_encoded', 'cand_param1_encoded',\n",
    "    'same_param2', 'base_param2_encoded', 'cand_param2_encoded'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['is_double']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3a793",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb567592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, \n",
    "                            precision_recall_curve, f1_score, \n",
    "                            classification_report)\n",
    "import lightgbm as lgb\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ee68dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметр для LightGBM, учитывающий дисбаланс данных\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train) \n",
    "\n",
    "base_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'average_precision',\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1,\n",
    "    'min_child_weight': 0.01,\n",
    "    'min_split_gain': 0.0,\n",
    "    'path_smooth': 0.1\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.1),\n",
    "    'num_leaves': randint(20, 50),\n",
    "    'max_depth': randint(3, 8),\n",
    "    'min_child_samples': randint(30, 100),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "    'subsample': uniform(0.7, 0.3),  # от 0.6 до 1.0\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'feature_fraction': uniform(0.7, 0.3),\n",
    "    'bagging_freq': randint(3, 10),\n",
    "    'extra_trees': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d5bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's average_precision: 0.601922\tvalid's average_precision: 0.584793\n",
      "[200]\ttrain's average_precision: 0.648811\tvalid's average_precision: 0.617029\n",
      "[300]\ttrain's average_precision: 0.680852\tvalid's average_precision: 0.632404\n",
      "[400]\ttrain's average_precision: 0.706711\tvalid's average_precision: 0.64239\n",
      "[500]\ttrain's average_precision: 0.730659\tvalid's average_precision: 0.651872\n",
      "[600]\ttrain's average_precision: 0.748827\tvalid's average_precision: 0.657182\n",
      "[700]\ttrain's average_precision: 0.76716\tvalid's average_precision: 0.662164\n",
      "[800]\ttrain's average_precision: 0.783674\tvalid's average_precision: 0.666262\n",
      "[900]\ttrain's average_precision: 0.799028\tvalid's average_precision: 0.669834\n",
      "[1000]\ttrain's average_precision: 0.812409\tvalid's average_precision: 0.672854\n",
      "Fold 1 AP: 0.6729\n",
      "Fold 1 Calibrated AP: 0.6642\n",
      "Fold 1 Optimal threshold: 0.3696\n",
      "[100]\ttrain's average_precision: 0.606289\tvalid's average_precision: 0.569553\n",
      "[200]\ttrain's average_precision: 0.650959\tvalid's average_precision: 0.599336\n",
      "[300]\ttrain's average_precision: 0.685175\tvalid's average_precision: 0.618289\n",
      "[400]\ttrain's average_precision: 0.7095\tvalid's average_precision: 0.629104\n",
      "[500]\ttrain's average_precision: 0.731809\tvalid's average_precision: 0.638629\n",
      "[600]\ttrain's average_precision: 0.749947\tvalid's average_precision: 0.644448\n",
      "[700]\ttrain's average_precision: 0.766952\tvalid's average_precision: 0.649235\n",
      "[800]\ttrain's average_precision: 0.783859\tvalid's average_precision: 0.653757\n",
      "[900]\ttrain's average_precision: 0.798176\tvalid's average_precision: 0.657753\n",
      "[1000]\ttrain's average_precision: 0.81162\tvalid's average_precision: 0.659605\n",
      "Fold 2 AP: 0.6596\n",
      "Fold 2 Calibrated AP: 0.6517\n",
      "Fold 2 Optimal threshold: 0.3103\n",
      "[100]\ttrain's average_precision: 0.600144\tvalid's average_precision: 0.5882\n",
      "[200]\ttrain's average_precision: 0.649734\tvalid's average_precision: 0.620165\n",
      "[300]\ttrain's average_precision: 0.681369\tvalid's average_precision: 0.634606\n",
      "[400]\ttrain's average_precision: 0.707955\tvalid's average_precision: 0.646381\n",
      "[500]\ttrain's average_precision: 0.729421\tvalid's average_precision: 0.654519\n",
      "[600]\ttrain's average_precision: 0.74861\tvalid's average_precision: 0.659809\n",
      "[700]\ttrain's average_precision: 0.76666\tvalid's average_precision: 0.664714\n",
      "[800]\ttrain's average_precision: 0.782088\tvalid's average_precision: 0.668294\n",
      "[900]\ttrain's average_precision: 0.796745\tvalid's average_precision: 0.671894\n",
      "[1000]\ttrain's average_precision: 0.811372\tvalid's average_precision: 0.675149\n",
      "Fold 3 AP: 0.6753\n",
      "Fold 3 Calibrated AP: 0.6682\n",
      "Fold 3 Optimal threshold: 0.3639\n",
      "[100]\ttrain's average_precision: 0.602352\tvalid's average_precision: 0.584499\n",
      "[200]\ttrain's average_precision: 0.652313\tvalid's average_precision: 0.62202\n",
      "[300]\ttrain's average_precision: 0.684341\tvalid's average_precision: 0.640862\n",
      "[400]\ttrain's average_precision: 0.709053\tvalid's average_precision: 0.650213\n",
      "[500]\ttrain's average_precision: 0.730642\tvalid's average_precision: 0.657299\n",
      "[600]\ttrain's average_precision: 0.749329\tvalid's average_precision: 0.662653\n",
      "[700]\ttrain's average_precision: 0.767467\tvalid's average_precision: 0.667745\n",
      "[800]\ttrain's average_precision: 0.783241\tvalid's average_precision: 0.671131\n",
      "[900]\ttrain's average_precision: 0.798119\tvalid's average_precision: 0.673517\n",
      "[1000]\ttrain's average_precision: 0.812588\tvalid's average_precision: 0.676574\n",
      "Fold 4 AP: 0.6766\n",
      "Fold 4 Calibrated AP: 0.6690\n",
      "Fold 4 Optimal threshold: 0.3436\n",
      "[100]\ttrain's average_precision: 0.606339\tvalid's average_precision: 0.586746\n",
      "[200]\ttrain's average_precision: 0.652266\tvalid's average_precision: 0.61847\n",
      "[300]\ttrain's average_precision: 0.686289\tvalid's average_precision: 0.637107\n",
      "[400]\ttrain's average_precision: 0.710185\tvalid's average_precision: 0.646517\n",
      "[500]\ttrain's average_precision: 0.73219\tvalid's average_precision: 0.654008\n",
      "[600]\ttrain's average_precision: 0.751749\tvalid's average_precision: 0.659984\n",
      "[700]\ttrain's average_precision: 0.768746\tvalid's average_precision: 0.663986\n",
      "[800]\ttrain's average_precision: 0.784735\tvalid's average_precision: 0.668323\n",
      "[900]\ttrain's average_precision: 0.800339\tvalid's average_precision: 0.671434\n",
      "[1000]\ttrain's average_precision: 0.814637\tvalid's average_precision: 0.674309\n",
      "Fold 5 AP: 0.6743\n",
      "Fold 5 Calibrated AP: 0.6664\n",
      "Fold 5 Optimal threshold: 0.3404\n"
     ]
    }
   ],
   "source": [
    "# Внешняя кросс-валидация для оценки модели\n",
    "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Внутренняя кросс-валидация для подбора параметров\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Для хранения калиброванных предсказаний\n",
    "test_preds = np.zeros(len(X_test))\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "models = []\n",
    "calibrators = []\n",
    "thresholds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv_outer.split(X_train, y_train)):\n",
    "    X_train_cross, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_cross, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Подбор параметров на внутренней кросс-валидации\n",
    "    lgbm = lgb.LGBMClassifier(**base_params)\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        scoring='average_precision',\n",
    "        cv=cv_inner,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train_cross, y_train_cross)\n",
    "    best_params = search.best_params_\n",
    "    final_params = {**base_params, **best_params}\n",
    "    \n",
    "    # Обучение модели с лучшими параметрами\n",
    "    train_data = lgb.Dataset(X_train_cross, label=y_train_cross)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        final_params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Получение предсказаний для валидационного набора\n",
    "    val_preds = model.predict(X_val)\n",
    "    oof_preds[val_idx] = val_preds\n",
    "    \n",
    "    # Калибровка на валидационном наборе\n",
    "    calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "    calibrator.fit(val_preds, y_val)\n",
    "    \n",
    "    # Оптимизация порога по F1\n",
    "    precisions, recalls, threshs = precision_recall_curve(y_val, calibrator.predict(val_preds))\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = threshs[optimal_idx]\n",
    "    \n",
    "    # Сохранение модели и калибратора\n",
    "    models.append(model)\n",
    "    calibrators.append(calibrator)\n",
    "    thresholds.append(optimal_threshold)\n",
    "    \n",
    "    # Предсказание на тестовом наборе\n",
    "    test_preds += model.predict(X_test) / cv_outer.get_n_splits()\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AP: {average_precision_score(y_val, val_preds):.4f}\")\n",
    "    print(f\"Fold {fold + 1} Calibrated AP: {average_precision_score(y_val, calibrator.predict(val_preds)):.4f}\")\n",
    "    print(f\"Fold {fold + 1} Optimal threshold: {optimal_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ebc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation:\n",
      "OOF MAP: 0.6717\n",
      "OOF Calibrated MAP: 0.6666\n",
      "Test MAP: 0.6758\n",
      "\n",
      "Classification Report (at optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     93882\n",
      "           1       0.67      0.59      0.63      6118\n",
      "\n",
      "    accuracy                           0.96    100000\n",
      "   macro avg       0.82      0.78      0.80    100000\n",
      "weighted avg       0.95      0.96      0.96    100000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0          92095  1787\n",
      "1           2519  3599\n"
     ]
    }
   ],
   "source": [
    "# Калибровка на всех OOF предсказаниях (финальный калибратор)\n",
    "final_calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "final_calibrator.fit(oof_preds, y_train)\n",
    "\n",
    "# Оптимизация порога на всех OOF предсказаниях\n",
    "precisions, recalls, threshs = precision_recall_curve(y_train, final_calibrator.predict(oof_preds))\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "final_threshold = threshs[optimal_idx]\n",
    "\n",
    "# Калибровка тестовых предсказаний\n",
    "test_calibrated = final_calibrator.predict(test_preds)\n",
    "test_pred = (test_calibrated >= final_threshold).astype(int)\n",
    "\n",
    "# Оценка модели\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "print(f\"OOF MAP: {average_precision_score(y_train, oof_preds):.4f}\")\n",
    "print(f\"OOF Calibrated MAP: {average_precision_score(y_train, final_calibrator.predict(oof_preds)):.4f}\")\n",
    "print(f\"Test MAP: {average_precision_score(y_test, test_calibrated):.4f}\")\n",
    "print(\"\\nClassification Report (at optimal threshold):\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.crosstab(y_test, test_pred, rownames=['Actual'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c21b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and all assets saved to 'best_model_assets_2.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "model_assets = {\n",
    "    'models': models,\n",
    "    'final_calibrator': final_calibrator,\n",
    "    'optimal_threshold': final_threshold,\n",
    "    'features': features,\n",
    "    'calibrators': calibrators,\n",
    "    'params': final_params,\n",
    "    'performance': {\n",
    "        'test_map': average_precision_score(y_test, test_calibrated),\n",
    "        'test_f1': f1_score(y_test, test_pred),\n",
    "        'oof_map': average_precision_score(y_train, oof_preds),\n",
    "        'oof_calibrated_map': average_precision_score(y_train, final_calibrator.predict(oof_preds))\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(model_assets, '../data/models/best_model_assets_2.joblib')\n",
    "print(\"\\nModel and all assets saved to 'best_model_assets_2.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
